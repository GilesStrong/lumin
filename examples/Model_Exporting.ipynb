{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# N.B. This example is highly out of date please proceed with caution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model exporting\n",
    "Sometimes your model runtime environment may be different your training environment, and this can sometimes involve changing tools, e.g. CMS has a Tensorflow interface built in to its main software package. If your runtime does not yet support PyTorch, you may need to export your trained models in a format that they can then be applied in production.\n",
    "LUMIN currently has limited, experimental support for exporting to [ONNX](https://github.com/onnx/onnx) (open standard format for representing machine learning models), and [Tensorflow](https://www.tensorflow.org/) Protocolbuffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "SAVE_PATH = Path('weights/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll begin by loading a model that was trained during the Binary Classification example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lumin.nn.models.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SAVE_PATH/'Binary_Classification_builder.pkl', 'rb') as fin: model_builder = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.from_save(SAVE_PATH/'Binary_Classification_0.h5', model_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inputs:\n",
       "30 Continuous: ['DER_mass_MMC', 'DER_mass_transverse_met_lep', 'DER_mass_vis', 'DER_pt_h', 'DER_deltaeta_jet_jet', 'DER_mass_jet_jet', 'DER_prodeta_jet_jet', 'DER_deltar_tau_lep', 'DER_pt_tot', 'DER_sum_pt', 'DER_pt_ratio_lep_tau', 'DER_met_phi_centrality', 'DER_lep_eta_centrality', 'PRI_met_sumet', 'PRI_jet_all_pt', 'PRI_met_px', 'PRI_met_py', 'PRI_jet_leading_px', 'PRI_jet_leading_py', 'PRI_jet_leading_pz', 'PRI_lep_px', 'PRI_lep_py', 'PRI_lep_pz', 'PRI_jet_subleading_px', 'PRI_jet_subleading_py', 'PRI_jet_subleading_pz', 'PRI_tau_px', 'PRI_tau_py', 'PRI_tau_pz', 'PRI_met_pt']\n",
       "                   \n",
       "1  Categorical: ['PRI_jet_num']\n",
       "                   \n",
       "0  Matrix elements: []\n",
       "                   \n",
       "\n",
       "Model:\n",
       "<bound method Module.parameters of Sequential(\n",
       "  (0): CatEmbHead(\n",
       "    (embeds): ModuleList(\n",
       "      (0): Embedding(4, 2)\n",
       "    )\n",
       "  )\n",
       "  (1): FullyConnected(\n",
       "    (layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "        (1): Swish()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "        (1): Swish()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Linear(in_features=96, out_features=32, bias=True)\n",
       "        (1): Swish()\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Linear(in_features=128, out_features=32, bias=True)\n",
       "        (1): Swish()\n",
       "      )\n",
       "      (4): Sequential(\n",
       "        (0): Linear(in_features=160, out_features=32, bias=True)\n",
       "        (1): Swish()\n",
       "      )\n",
       "      (5): Sequential(\n",
       "        (0): Linear(in_features=192, out_features=32, bias=True)\n",
       "        (1): Swish()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): ClassRegMulti(\n",
       "    (dense): Linear(in_features=32, out_features=1, bias=True)\n",
       "    (act): Sigmoid()\n",
       "  )\n",
       ")>\n",
       "                   \n",
       "\n",
       "Number of trainable parameters: 21737\n",
       "                   \n",
       "\n",
       "Optimiser:\n",
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9499999949931391, 0.999)\n",
       "    capturable: False\n",
       "    differentiable: False\n",
       "    eps: 1e-08\n",
       "    foreach: None\n",
       "    fused: None\n",
       "    lr: 5.006860859246842e-10\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")\n",
       "                   \n",
       "\n",
       "Loss:\n",
       "<class 'torch.nn.modules.loss.BCELoss'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to export to ONNX, we need to hardcode a batch size for the data that will be fed through the model during runtime. Since in a physics analysis, data is normally processed serially, we'll set the batchsize to one. Note: Ensemble also has a `/export2onnx` method which will export all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "OnnxExporterError",
     "evalue": "Module onnx is not installed!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/code/lumin/.venv/lib/python3.10/site-packages/torch/onnx/_internal/onnx_proto_utils.py:215\u001b[0m, in \u001b[0;36m_add_onnxscript_fn\u001b[0;34m(model_bytes, custom_opsets)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 215\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'onnx'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOnnxExporterError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport2onnx\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSAVE_PATH\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mBinary_Classification\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/lumin/lumin/nn/models/model.py:599\u001b[0m, in \u001b[0;36mModel.export2onnx\u001b[0;34m(self, name, bs)\u001b[0m\n\u001b[1;32m    597\u001b[0m     name \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.onnx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    598\u001b[0m dummy_input \u001b[38;5;241m=\u001b[39m to_device(torch\u001b[38;5;241m.\u001b[39mrand(bs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_builder\u001b[38;5;241m.\u001b[39mn_cont_in \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_builder\u001b[38;5;241m.\u001b[39mcat_embedder\u001b[38;5;241m.\u001b[39mn_cat_in))\n\u001b[0;32m--> 599\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43monnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdummy_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/code/lumin/.venv/lib/python3.10/site-packages/torch/onnx/__init__.py:375\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, kwargs, export_params, verbose, input_names, output_names, opset_version, dynamic_axes, keep_initializers_as_inputs, dynamo, external_data, dynamic_shapes, report, verify, profile, dump_exported_program, artifacts_dir, fallback, training, operator_export_type, do_constant_folding, custom_opsets, export_modules_as_functions, autograd_inlining, **_)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dynamic_shapes:\n\u001b[1;32m    370\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    371\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe exporter only supports dynamic shapes \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    372\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthrough parameter dynamic_axes when dynamo=False.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    373\u001b[0m     )\n\u001b[0;32m--> 375\u001b[0m \u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    384\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    388\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    391\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    394\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/code/lumin/.venv/lib/python3.10/site-packages/torch/onnx/utils.py:502\u001b[0m, in \u001b[0;36mexport\u001b[0;34m(model, args, f, kwargs, export_params, verbose, training, input_names, output_names, operator_export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, custom_opsets, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m    499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m     args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;241m+\u001b[39m (kwargs,)\n\u001b[0;32m--> 502\u001b[0m \u001b[43m_export\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    503\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    504\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    511\u001b[0m \u001b[43m    \u001b[49m\u001b[43moperator_export_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moperator_export_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    512\u001b[0m \u001b[43m    \u001b[49m\u001b[43mopset_version\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mopset_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    513\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdo_constant_folding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdo_constant_folding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdynamic_axes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdynamic_axes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    515\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_initializers_as_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    516\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    517\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexport_modules_as_functions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m    \u001b[49m\u001b[43mautograd_inlining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mautograd_inlining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    519\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/code/lumin/.venv/lib/python3.10/site-packages/torch/onnx/utils.py:1640\u001b[0m, in \u001b[0;36m_export\u001b[0;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, opset_version, do_constant_folding, dynamic_axes, keep_initializers_as_inputs, fixed_batch_size, custom_opsets, add_node_names, onnx_shape_inference, export_modules_as_functions, autograd_inlining)\u001b[0m\n\u001b[1;32m   1621\u001b[0m     (\n\u001b[1;32m   1622\u001b[0m         proto,\n\u001b[1;32m   1623\u001b[0m         export_map,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1637\u001b[0m         node_attr_to_name,\n\u001b[1;32m   1638\u001b[0m     )\n\u001b[1;32m   1639\u001b[0m \u001b[38;5;66;03m# insert function_proto into model_proto.\u001b[39;00m\n\u001b[0;32m-> 1640\u001b[0m proto \u001b[38;5;241m=\u001b[39m \u001b[43monnx_proto_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_add_onnxscript_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproto\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_opsets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1643\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m   1645\u001b[0m     torch\u001b[38;5;241m.\u001b[39monnx\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExported graph: \u001b[39m\u001b[38;5;124m\"\u001b[39m, graph)\n",
      "File \u001b[0;32m~/code/lumin/.venv/lib/python3.10/site-packages/torch/onnx/_internal/onnx_proto_utils.py:217\u001b[0m, in \u001b[0;36m_add_onnxscript_fn\u001b[0;34m(model_bytes, custom_opsets)\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01monnx\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 217\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOnnxExporterError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModule onnx is not installed!\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;66;03m# For > 2GB model, onnx.load_fromstring would fail. However, because\u001b[39;00m\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# in _export_onnx, the tensors should be saved separately if the proto\u001b[39;00m\n\u001b[1;32m    221\u001b[0m \u001b[38;5;66;03m# size > 2GB, and if it for some reason did not, the model would fail on\u001b[39;00m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;66;03m# serialization anyway in terms of the protobuf limitation. So we don't\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[38;5;66;03m# need to worry about > 2GB model getting here.\u001b[39;00m\n\u001b[1;32m    224\u001b[0m model_proto \u001b[38;5;241m=\u001b[39m onnx\u001b[38;5;241m.\u001b[39mload_model_from_string(model_bytes)  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n",
      "\u001b[0;31mOnnxExporterError\u001b[0m: Module onnx is not installed!"
     ]
    }
   ],
   "source": [
    "model.export2onnx(str(SAVE_PATH/'Binary_Classification'), bs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load the exported model to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "onnx_model = onnx.load(SAVE_PATH/'Binary_Classification.onnx')\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph torch-jit-export (\n",
      "  %0[FLOAT, 1x31]\n",
      ") initializers (\n",
      "  %1[FLOAT, 4x2]\n",
      "  %2[FLOAT, 100x32]\n",
      "  %3[FLOAT, 100]\n",
      "  %4[FLOAT, 100x100]\n",
      "  %5[FLOAT, 100]\n",
      "  %6[FLOAT, 100x100]\n",
      "  %7[FLOAT, 100]\n",
      "  %8[FLOAT, 100x100]\n",
      "  %9[FLOAT, 100]\n",
      "  %10[FLOAT, 1x100]\n",
      "  %11[FLOAT, 1]\n",
      ") {\n",
      "  %12 = Slice[axes = [0], ends = [9223372036854775807], starts = [0]](%0)\n",
      "  %13 = Slice[axes = [1], ends = [9223372036854775807], starts = [30]](%12)\n",
      "  %14 = Cast[to = 7](%13)\n",
      "  %15 = Slice[axes = [0], ends = [9223372036854775807], starts = [0]](%14)\n",
      "  %16 = Constant[value = <Scalar Tensor []>]()\n",
      "  %17 = Gather[axis = 1](%15, %16)\n",
      "  %18 = Gather(%1, %17)\n",
      "  %19 = Concat[axis = 1](%18)\n",
      "  %20 = Slice[axes = [0], ends = [9223372036854775807], starts = [0]](%0)\n",
      "  %21 = Slice[axes = [1], ends = [30], starts = [0]](%20)\n",
      "  %22 = Concat[axis = 1](%21, %19)\n",
      "  %23 = Gemm[alpha = 1, beta = 1, transB = 1](%22, %2, %3)\n",
      "  %24 = Sigmoid(%23)\n",
      "  %25 = Mul(%23, %24)\n",
      "  %26 = Gemm[alpha = 1, beta = 1, transB = 1](%25, %4, %5)\n",
      "  %27 = Sigmoid(%26)\n",
      "  %28 = Mul(%26, %27)\n",
      "  %29 = Gemm[alpha = 1, beta = 1, transB = 1](%28, %6, %7)\n",
      "  %30 = Sigmoid(%29)\n",
      "  %31 = Mul(%29, %30)\n",
      "  %32 = Gemm[alpha = 1, beta = 1, transB = 1](%31, %8, %9)\n",
      "  %33 = Sigmoid(%32)\n",
      "  %34 = Mul(%32, %33)\n",
      "  %35 = Gemm[alpha = 1, beta = 1, transB = 1](%34, %10, %11)\n",
      "  %36 = Sigmoid(%35)\n",
      "  return %36\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(onnx.helper.printable_graph(onnx_model.graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And visualise it with netron to make sure it looks as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'weights/Binary_Classification.onnx' at http://localhost:8080\n"
     ]
    }
   ],
   "source": [
    "import netron\n",
    "netron.start(str(SAVE_PATH/'Binary_Classification.onnx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "Exporting to Tensorflow requires fir exporting to ONNX, then converting the ONNX file to a protocol buffer. Both exports can be performed using the `.export2tfpb` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Limited tf.compat.v2.summary API due to missing TensorBoard installation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/giles/anaconda3/lib/python3.6/site-packages/onnx_tf/handlers/backend/ceil.py:10: The name tf.ceil is deprecated. Please use tf.math.ceil instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giles/anaconda3/lib/python3.6/site-packages/onnx_tf/common/__init__.py:87: UserWarning: onnx_tf.common.get_outputs_names is deprecated. It will be removed in future release. Use TensorflowGraph.get_outputs_names instead.\n",
      "  warnings.warn(message)\n",
      "WARNING:tensorflow:From /home/giles/anaconda3/lib/python3.6/site-packages/onnx_tf/handlers/backend/ceil.py:10: The name tf.ceil is deprecated. Please use tf.math.ceil instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/giles/anaconda3/lib/python3.6/site-packages/onnx_tf/handlers/backend/depth_to_space.py:12: The name tf.depth_to_space is deprecated. Please use tf.compat.v1.depth_to_space instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/giles/anaconda3/lib/python3.6/site-packages/onnx_tf/handlers/backend/depth_to_space.py:12: The name tf.depth_to_space is deprecated. Please use tf.compat.v1.depth_to_space instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/giles/anaconda3/lib/python3.6/site-packages/onnx_tf/handlers/backend/erf.py:9: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/giles/anaconda3/lib/python3.6/site-packages/onnx_tf/handlers/backend/erf.py:9: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/giles/anaconda3/lib/python3.6/site-packages/onnx_tf/handlers/backend/is_nan.py:9: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/giles/anaconda3/lib/python3.6/site-packages/onnx_tf/handlers/backend/is_nan.py:9: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/giles/anaconda3/lib/python3.6/site-packages/onnx_tf/handlers/backend/log.py:10: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/giles/anaconda3/lib/python3.6/site-packages/onnx_tf/handlers/backend/log.py:10: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/giles/anaconda3/lib/python3.6/site-packages/onnx_tf/handlers/backend/upsample.py:13: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/giles/anaconda3/lib/python3.6/site-packages/onnx_tf/handlers/backend/upsample.py:13: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/giles/anaconda3/lib/python3.6/site-packages/onnx_tf/handlers/backend/gemm.py:14: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giles/cernbox/lumin/lumin/nn/models/model.py:423: UserWarning: Tensorflow ProtocolBuffer export of LUMIN models (via ONNX) has not been fully explored or sufficiently tested yet.\n",
      "                         Please use with caution, and report any trouble\n",
      "  Please use with caution, and report any trouble\"\"\")\n",
      "/home/giles/cernbox/lumin/lumin/nn/models/model.py:405: UserWarning: ONNX export of LUMIN models has not been fully explored or sufficiently tested yet.\n",
      "                         Please use with caution, and report any trouble\n",
      "  Please use with caution, and report any trouble\"\"\")\n",
      "/home/giles/anaconda3/lib/python3.6/site-packages/onnx_tf/common/handler_helper.py:37: UserWarning: Unknown op ConstantFill in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/home/giles/anaconda3/lib/python3.6/site-packages/onnx_tf/common/handler_helper.py:37: UserWarning: Unknown op ImageScaler in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/home/giles/anaconda3/lib/python3.6/site-packages/onnx_tf/common/handler_helper.py:34: UserWarning: Fail to get since_version of IsInf in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "/home/giles/anaconda3/lib/python3.6/site-packages/onnx_tf/common/handler_helper.py:34: UserWarning: Fail to get since_version of Mod in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "/home/giles/anaconda3/lib/python3.6/site-packages/onnx_tf/common/handler_helper.py:34: UserWarning: Fail to get since_version of ThresholdedRelu in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "WARNING:tensorflow:From /home/giles/anaconda3/lib/python3.6/site-packages/onnx_tf/handlers/backend/gemm.py:14: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    }
   ],
   "source": [
    "model.export2tfpb(str(SAVE_PATH/'Binary_Classification.pb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually, this involves running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx_tf.backend import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/giles/anaconda3/lib/python3.6/site-packages/onnx_tf/common/handler_helper.py:37: UserWarning: Unknown op ConstantFill in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/home/giles/anaconda3/lib/python3.6/site-packages/onnx_tf/common/handler_helper.py:37: UserWarning: Unknown op ImageScaler in domain `ai.onnx`.\n",
      "  handler.ONNX_OP, handler.DOMAIN or \"ai.onnx\"))\n",
      "/home/giles/anaconda3/lib/python3.6/site-packages/onnx_tf/common/handler_helper.py:34: UserWarning: Fail to get since_version of IsInf in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "/home/giles/anaconda3/lib/python3.6/site-packages/onnx_tf/common/handler_helper.py:34: UserWarning: Fail to get since_version of Mod in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n",
      "/home/giles/anaconda3/lib/python3.6/site-packages/onnx_tf/common/handler_helper.py:34: UserWarning: Fail to get since_version of ThresholdedRelu in domain `` with max_inclusive_version=9. Set to 1.\n",
      "  handler.ONNX_OP, handler.DOMAIN, version))\n"
     ]
    }
   ],
   "source": [
    "tf_rep = prepare(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0']\n",
      "-----\n",
      "['36']\n",
      "-----\n",
      "{'1': <tf.Tensor 'Const:0' shape=(4, 2) dtype=float32>, '2': <tf.Tensor 'Const_1:0' shape=(100, 32) dtype=float32>, '3': <tf.Tensor 'Const_2:0' shape=(100,) dtype=float32>, '4': <tf.Tensor 'Const_3:0' shape=(100, 100) dtype=float32>, '5': <tf.Tensor 'Const_4:0' shape=(100,) dtype=float32>, '6': <tf.Tensor 'Const_5:0' shape=(100, 100) dtype=float32>, '7': <tf.Tensor 'Const_6:0' shape=(100,) dtype=float32>, '8': <tf.Tensor 'Const_7:0' shape=(100, 100) dtype=float32>, '9': <tf.Tensor 'Const_8:0' shape=(100,) dtype=float32>, '10': <tf.Tensor 'Const_9:0' shape=(1, 100) dtype=float32>, '11': <tf.Tensor 'Const_10:0' shape=(1,) dtype=float32>, '0': <tf.Tensor '0:0' shape=(1, 31) dtype=float32>, '12': <tf.Tensor 'Slice:0' shape=(1, 31) dtype=float32>, '13': <tf.Tensor 'Slice_1:0' shape=(1, 1) dtype=float32>, '14': <tf.Tensor 'Cast:0' shape=(1, 1) dtype=int64>, '15': <tf.Tensor 'Slice_2:0' shape=(1, 1) dtype=int64>, '16': <tf.Tensor 'Const_17:0' shape=() dtype=int64>, '17': <tf.Tensor 'GatherV2:0' shape=(1,) dtype=int64>, '18': <tf.Tensor 'GatherV2_1:0' shape=(1, 2) dtype=float32>, '19': <tf.Tensor 'concat:0' shape=(1, 2) dtype=float32>, '20': <tf.Tensor 'Slice_3:0' shape=(1, 31) dtype=float32>, '21': <tf.Tensor 'Slice_4:0' shape=(1, 30) dtype=float32>, '22': <tf.Tensor 'concat_1:0' shape=(1, 32) dtype=float32>, '23': <tf.Tensor 'add:0' shape=(1, 100) dtype=float32>, '24': <tf.Tensor 'Sigmoid:0' shape=(1, 100) dtype=float32>, '25': <tf.Tensor 'Mul_2:0' shape=(1, 100) dtype=float32>, '26': <tf.Tensor 'add_1:0' shape=(1, 100) dtype=float32>, '27': <tf.Tensor 'Sigmoid_1:0' shape=(1, 100) dtype=float32>, '28': <tf.Tensor 'Mul_5:0' shape=(1, 100) dtype=float32>, '29': <tf.Tensor 'add_2:0' shape=(1, 100) dtype=float32>, '30': <tf.Tensor 'Sigmoid_2:0' shape=(1, 100) dtype=float32>, '31': <tf.Tensor 'Mul_8:0' shape=(1, 100) dtype=float32>, '32': <tf.Tensor 'add_3:0' shape=(1, 100) dtype=float32>, '33': <tf.Tensor 'Sigmoid_3:0' shape=(1, 100) dtype=float32>, '34': <tf.Tensor 'Mul_11:0' shape=(1, 100) dtype=float32>, '35': <tf.Tensor 'add_4:0' shape=(1, 1) dtype=float32>, '36': <tf.Tensor 'Sigmoid_4:0' shape=(1, 1) dtype=float32>}\n"
     ]
    }
   ],
   "source": [
    "print(tf_rep.inputs) # Input nodes to the model\n",
    "print('-----')\n",
    "print(tf_rep.outputs) # Output nodes from the model\n",
    "print('-----')\n",
    "print(tf_rep.tensor_dict) # All nodes in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_rep.export_graph(SAVE_PATH/'Binary_Classification.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
