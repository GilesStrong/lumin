{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model exporting\n",
    "Sometimes your model runtime environment may be different your training environment, and this can sometimes involve changing tools, e.g. CMS has a Tensorflow interface built in to its main software package. If your runtime does not yet support PyTorch, you may need to export your trained models in a format that they can then be applied in production.\n",
    "LUMIN currently has limited, experimental support for exporting to [ONNX](https://github.com/onnx/onnx) (open standard format for representing machine learning models), and [Tensorflow](https://www.tensorflow.org/) Protocolbuffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "SAVE_PATH = Path('weights/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll begin by loading a model that was trained during the Binary Classification example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lumin.nn.models.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(SAVE_PATH/'Binary_Classification_builder.pkl', 'rb') as fin: model_builder = pickle.load(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model.from_save(SAVE_PATH/'Binary_Classification_0.h5', model_builder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model:\n",
       "<bound method Module.parameters of Sequential(\n",
       "  (0): CatEmbHead(\n",
       "    (embeds): ModuleList(\n",
       "      (0): Embedding(4, 2)\n",
       "    )\n",
       "  )\n",
       "  (1): FullyConnected(\n",
       "    (layers): ModuleList(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=32, out_features=100, bias=True)\n",
       "        (1): Swish()\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (1): Swish()\n",
       "      )\n",
       "      (2): Sequential(\n",
       "        (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (1): Swish()\n",
       "      )\n",
       "      (3): Sequential(\n",
       "        (0): Linear(in_features=100, out_features=100, bias=True)\n",
       "        (1): Swish()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (2): ClassRegMulti(\n",
       "    (dense): Linear(in_features=100, out_features=1, bias=True)\n",
       "    (act): Sigmoid()\n",
       "  )\n",
       ")>\n",
       "                   \n",
       "\n",
       "Number of trainable parameters: 33709\n",
       "                   \n",
       "\n",
       "Optimiser:\n",
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.0004272996042924875\n",
       "    weight_decay: 0\n",
       ")\n",
       "                   \n",
       "\n",
       "Loss:\n",
       "<class 'torch.nn.modules.loss.BCELoss'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ONNX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to export to ONNX, we need to hardcode a batch size for the data that will be fed through the model during runtime. Since in a physics analysis, data is normally processed serially, we'll set the batchsize to one. Note: Ensemble also has a `/export2onnx` method which will export all models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.export2onnx(str(SAVE_PATH/'Binary_Classification'), bs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can load the exported model to check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "onnx_model = onnx.load(SAVE_PATH/'Binary_Classification.onnx')\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph torch-jit-export (\n",
      "  %0[FLOAT, 1x31]\n",
      ") initializers (\n",
      "  %0.embeds.0.weight[FLOAT, 4x2]\n",
      "  %1.layers.0.0.weight[FLOAT, 100x32]\n",
      "  %1.layers.0.0.bias[FLOAT, 100]\n",
      "  %1.layers.1.0.weight[FLOAT, 100x100]\n",
      "  %1.layers.1.0.bias[FLOAT, 100]\n",
      "  %1.layers.2.0.weight[FLOAT, 100x100]\n",
      "  %1.layers.2.0.bias[FLOAT, 100]\n",
      "  %1.layers.3.0.weight[FLOAT, 100x100]\n",
      "  %1.layers.3.0.bias[FLOAT, 100]\n",
      "  %2.dense.weight[FLOAT, 1x100]\n",
      "  %2.dense.bias[FLOAT, 1]\n",
      ") {\n",
      "  %12 = Slice[axes = [1], ends = [9223372036854775807], starts = [30]](%0)\n",
      "  %13 = Cast[to = 7](%12)\n",
      "  %14 = Constant[value = <Scalar Tensor []>]()\n",
      "  %15 = Gather[axis = 1](%13, %14)\n",
      "  %16 = Gather(%0.embeds.0.weight, %15)\n",
      "  %17 = Concat[axis = 1](%16)\n",
      "  %18 = Slice[axes = [1], ends = [30], starts = [0]](%0)\n",
      "  %19 = Concat[axis = 1](%18, %17)\n",
      "  %20 = Gemm[alpha = 1, beta = 1, transB = 1](%19, %1.layers.0.0.weight, %1.layers.0.0.bias)\n",
      "  %21 = Sigmoid(%20)\n",
      "  %22 = Mul(%20, %21)\n",
      "  %23 = Gemm[alpha = 1, beta = 1, transB = 1](%22, %1.layers.1.0.weight, %1.layers.1.0.bias)\n",
      "  %24 = Sigmoid(%23)\n",
      "  %25 = Mul(%23, %24)\n",
      "  %26 = Gemm[alpha = 1, beta = 1, transB = 1](%25, %1.layers.2.0.weight, %1.layers.2.0.bias)\n",
      "  %27 = Sigmoid(%26)\n",
      "  %28 = Mul(%26, %27)\n",
      "  %29 = Gemm[alpha = 1, beta = 1, transB = 1](%28, %1.layers.3.0.weight, %1.layers.3.0.bias)\n",
      "  %30 = Sigmoid(%29)\n",
      "  %31 = Mul(%29, %30)\n",
      "  %32 = Gemm[alpha = 1, beta = 1, transB = 1](%31, %2.dense.weight, %2.dense.bias)\n",
      "  %33 = Sigmoid(%32)\n",
      "  return %33\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(onnx.helper.printable_graph(onnx_model.graph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And visualise it with netron to make sure it looks as expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'weights/Binary_Classification.onnx' at http://localhost:8080\n"
     ]
    }
   ],
   "source": [
    "import netron\n",
    "netron.start(str(SAVE_PATH/'Binary_Classification.onnx'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow\n",
    "Exporting to Tensorflow requires fir exporting to ONNX, then converting the ONNX file to a protocol buffer. Both exports can be performed using the `.export2tfpb` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0731 10:07:15.126302 139835358205760 deprecation_wrapper.py:119] From /home/giles/anaconda3/lib/python3.7/site-packages/onnx_tf/handlers/backend/ceil.py:10: The name tf.ceil is deprecated. Please use tf.math.ceil instead.\n",
      "\n",
      "W0731 10:07:15.128237 139835358205760 deprecation_wrapper.py:119] From /home/giles/anaconda3/lib/python3.7/site-packages/onnx_tf/handlers/backend/depth_to_space.py:12: The name tf.depth_to_space is deprecated. Please use tf.compat.v1.depth_to_space instead.\n",
      "\n",
      "W0731 10:07:15.129291 139835358205760 deprecation_wrapper.py:119] From /home/giles/anaconda3/lib/python3.7/site-packages/onnx_tf/handlers/backend/erf.py:9: The name tf.erf is deprecated. Please use tf.math.erf instead.\n",
      "\n",
      "W0731 10:07:15.398193 139835358205760 lazy_loader.py:50] \n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "W0731 10:07:15.399492 139835358205760 deprecation_wrapper.py:119] From /home/giles/anaconda3/lib/python3.7/site-packages/onnx_tf/handlers/backend/is_nan.py:9: The name tf.is_nan is deprecated. Please use tf.math.is_nan instead.\n",
      "\n",
      "W0731 10:07:15.400404 139835358205760 deprecation_wrapper.py:119] From /home/giles/anaconda3/lib/python3.7/site-packages/onnx_tf/handlers/backend/log.py:10: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "W0731 10:07:15.407693 139835358205760 deprecation_wrapper.py:119] From /home/giles/anaconda3/lib/python3.7/site-packages/onnx_tf/handlers/backend/upsample.py:13: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n",
      "\n",
      "W0731 10:07:15.454443 139835358205760 deprecation.py:323] From /home/giles/anaconda3/lib/python3.7/site-packages/onnx_tf/handlers/backend/gemm.py:14: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.flatten instead.\n"
     ]
    }
   ],
   "source": [
    "model.export2tfpb(str(SAVE_PATH/'Binary_Classification.pb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Manually, this involves running:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnx_tf.backend import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_rep = prepare(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0']\n",
      "-----\n",
      "['33']\n",
      "-----\n",
      "{'0.embeds.0.weight': <tf.Tensor 'Const:0' shape=(4, 2) dtype=float32>, '1.layers.0.0.bias': <tf.Tensor 'Const_1:0' shape=(100,) dtype=float32>, '1.layers.0.0.weight': <tf.Tensor 'Const_2:0' shape=(100, 32) dtype=float32>, '1.layers.1.0.bias': <tf.Tensor 'Const_3:0' shape=(100,) dtype=float32>, '1.layers.1.0.weight': <tf.Tensor 'Const_4:0' shape=(100, 100) dtype=float32>, '1.layers.2.0.bias': <tf.Tensor 'Const_5:0' shape=(100,) dtype=float32>, '1.layers.2.0.weight': <tf.Tensor 'Const_6:0' shape=(100, 100) dtype=float32>, '1.layers.3.0.bias': <tf.Tensor 'Const_7:0' shape=(100,) dtype=float32>, '1.layers.3.0.weight': <tf.Tensor 'Const_8:0' shape=(100, 100) dtype=float32>, '2.dense.bias': <tf.Tensor 'Const_9:0' shape=(1,) dtype=float32>, '2.dense.weight': <tf.Tensor 'Const_10:0' shape=(1, 100) dtype=float32>, '0': <tf.Tensor '0:0' shape=(1, 31) dtype=float32>, '12': <tf.Tensor 'Slice:0' shape=(1, 1) dtype=float32>, '13': <tf.Tensor 'Cast:0' shape=(1, 1) dtype=int64>, '14': <tf.Tensor 'Const_13:0' shape=() dtype=int64>, '15': <tf.Tensor 'GatherV2:0' shape=(1,) dtype=int64>, '16': <tf.Tensor 'GatherV2_1:0' shape=(1, 2) dtype=float32>, '17': <tf.Tensor 'concat:0' shape=(1, 2) dtype=float32>, '18': <tf.Tensor 'Slice_1:0' shape=(1, 30) dtype=float32>, '19': <tf.Tensor 'concat_1:0' shape=(1, 32) dtype=float32>, '20': <tf.Tensor 'add:0' shape=(1, 100) dtype=float32>, '21': <tf.Tensor 'Sigmoid:0' shape=(1, 100) dtype=float32>, '22': <tf.Tensor 'Mul_2:0' shape=(1, 100) dtype=float32>, '23': <tf.Tensor 'add_1:0' shape=(1, 100) dtype=float32>, '24': <tf.Tensor 'Sigmoid_1:0' shape=(1, 100) dtype=float32>, '25': <tf.Tensor 'Mul_5:0' shape=(1, 100) dtype=float32>, '26': <tf.Tensor 'add_2:0' shape=(1, 100) dtype=float32>, '27': <tf.Tensor 'Sigmoid_2:0' shape=(1, 100) dtype=float32>, '28': <tf.Tensor 'Mul_8:0' shape=(1, 100) dtype=float32>, '29': <tf.Tensor 'add_3:0' shape=(1, 100) dtype=float32>, '30': <tf.Tensor 'Sigmoid_3:0' shape=(1, 100) dtype=float32>, '31': <tf.Tensor 'Mul_11:0' shape=(1, 100) dtype=float32>, '32': <tf.Tensor 'add_4:0' shape=(1, 1) dtype=float32>, '33': <tf.Tensor 'Sigmoid_4:0' shape=(1, 1) dtype=float32>}\n"
     ]
    }
   ],
   "source": [
    "print(tf_rep.inputs) # Input nodes to the model\n",
    "print('-----')\n",
    "print(tf_rep.outputs) # Output nodes from the model\n",
    "print('-----')\n",
    "print(tf_rep.tensor_dict) # All nodes in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_rep.export_graph(SAVE_PATH/'Binary_Classification.pb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
